{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = code_example = \\\n",
    "\"\"\"# Handshake successful, kill previous client if there is any.\n",
    "with current_client_pid.get_lock():\n",
    "    old_pid = current_client_pid.value\n",
    "    if old_pid != 0:\n",
    "        print(f\"Booting previous client (pid={old_pid})\")\n",
    "        os.kill(old_pid, signal.SIGKILL)\n",
    "        current_client_pid.value = os.getpid()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, List\n",
    "import logging\n",
    "\n",
    "\n",
    "def get_src_tokens_and_logits(in_text: str, model_name: str, device: str = None, verbose=False) -> Tuple[List[str], Tensor]:\n",
    "    logging.basicConfig(level=logging.DEBUG if verbose else logging.INFO)\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    logging.info(f'Model: {model.__class__.__name__}')\n",
    "    logging.debug('Adding bos token...')\n",
    "    in_text = f'{tokenizer.bos_token}{in_text}'\n",
    "    logging.debug('Input:')\n",
    "    logging.debug(in_text)\n",
    "    logging.debug('------')\n",
    "    inputs: Tensor = tokenizer(in_text, return_tensors='pt').data['input_ids'].squeeze()\n",
    "    logging.debug(f\"Input token ids' shape: {inputs.shape}\")\n",
    "    if not device:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    logging.info(f'Device: {device}')\n",
    "    outputs: Tensor = model(inputs.to(torch.device(device)))\n",
    "    # NOTE: The last logit vector is used for predicting the next token, which is not part of the input. Therefore, we exclude it.\n",
    "    logging.debug('Discarding last logit vector...')\n",
    "    logits: Tensor = outputs.logits.data[:-1]\n",
    "    logging.debug(f'logits.shape: {logits.shape}')\n",
    "    # tokens: List[str] = tokenizer.convert_ids_to_tokens(inputs[1:])\n",
    "    src_tokens: List[str] = tokenizer.batch_decode([[i] for i in inputs[1:]])\n",
    "    return src_tokens, logits\n",
    "\n",
    "def get_scores(logits: Tensor, verbose=False) -> Tensor:\n",
    "    logging.basicConfig(level=logging.DEBUG if verbose else logging.INFO)\n",
    "    ret: Tensor = torch.distributions.Categorical(logits=logits).entropy()\n",
    "    logging.debug(f'scores.shape: {ret.shape}')\n",
    "    return ret\n",
    "\n",
    "# def get_topk(logits: Tensor, topk: int = 5):\n",
    "#     topk_prob_values, topk_prob_inds = torch.topk(logits, k=topk, dim=1)\n",
    "#     return topk_prob_values, topk_prob_inds\n",
    "\n",
    "# tokens, logits = get_src_tokens_and_logits(code_example, model_name='Salesforce/codegen-350M-mono')\n",
    "# scores = get_scores(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits -= logits.min(dim=-1, keepdim=True).values\n",
    "# logits /= logits.max(dim=-1, keepdim=True).values\n",
    "# logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_colors(scores: Tensor) -> List[str]:\n",
    "    cmap = mpl.colormaps['YlOrBr']\n",
    "    norm = mpl.colors.Normalize(vmin=scores.min(), vmax=scores.max())\n",
    "    rgbas: np.ndarray = cmap(norm(scores))\n",
    "    return np.apply_along_axis(mpl.colors.rgb2hex, -1, rgbas)\n",
    "\n",
    "def get_html(in_text: str):\n",
    "        tokens, logits = get_src_tokens_and_logits(in_text, model_name='Salesforce/codegen-350M-mono')\n",
    "        scores = get_scores(logits)\n",
    "        colors = get_colors(scores)\n",
    "        assert len(tokens) == len(colors), f'len(tokens)={len(tokens)} != len(colors)={len(colors)}'\n",
    "        ret = ''.join([f'<span style=\"background-color: {c}\" title=\"token={t}, score={s:.5f}\">{t}</span>' for t, s, c in zip(tokens, scores, colors)])\n",
    "        return f'<pre><code class=\"python\">{ret}</code></pre>'\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_html,\n",
    "    inputs=gr.Textbox(label='Code example', placeholder=code_example, value=code_example),\n",
    "    outputs=gr.Markdown()\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gr.close_all()\n",
    "    demo.launch(server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model: CodeGenForCausalLM\n",
      "INFO:root:Device: cpu\n",
      "/Users/nadavt/opt/anaconda3/envs/detecting-fake-text/lib/python3.8/site-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorCompare.cpp:413.)\n",
      "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre><code class=\"python\"><span style=\"background-color: #e2650f\" title=\"token=#, score=4.11538\">#</span><span style=\"background-color: #ce4f03\" title=\"token= Hand, score=4.57765\"> Hand</span><span style=\"background-color: #fea937\" title=\"token=shake, score=2.83114\">shake</span><span style=\"background-color: #762a05\" title=\"token= successful, score=5.93905\"> successful</span><span style=\"background-color: #eb6f14\" title=\"token=,, score=3.88495\">,</span><span style=\"background-color: #662506\" title=\"token= kill, score=6.19898\"> kill</span><span style=\"background-color: #a33904\" title=\"token= previous, score=5.26925\"> previous</span><span style=\"background-color: #842e05\" title=\"token= client, score=5.72638\"> client</span><span style=\"background-color: #feb340\" title=\"token= if, score=2.62907\"> if</span><span style=\"background-color: #d65808\" title=\"token= there, score=4.38367\"> there</span><span style=\"background-color: #fed16b\" title=\"token= is, score=1.98919\"> is</span><span style=\"background-color: #fec34f\" title=\"token= any, score=2.32501\"> any</span><span style=\"background-color: #fedb80\" title=\"token=., score=1.75364\">.</span><span style=\"background-color: #ffefaa\" title=\"token=\n, score=1.10092\">\n</span><span style=\"background-color: #fece65\" title=\"token=with, score=2.06497\">with</span><span style=\"background-color: #f4811d\" title=\"token= current, score=3.55418\"> current</span><span style=\"background-color: #fffbd2\" title=\"token=_, score=0.38007\">_</span><span style=\"background-color: #fea231\" title=\"token=client, score=2.94255\">client</span><span style=\"background-color: #fecf67\" title=\"token=_, score=2.04074\">_</span><span style=\"background-color: #d65808\" title=\"token=pid, score=4.40225\">pid</span><span style=\"background-color: #fec859\" title=\"token=., score=2.22448\">.</span><span style=\"background-color: #ee7617\" title=\"token=get, score=3.76673\">get</span><span style=\"background-color: #fffbd3\" title=\"token=_, score=0.34031\">_</span><span style=\"background-color: #fee595\" title=\"token=lock, score=1.48407\">lock</span><span style=\"background-color: #fff9c6\" title=\"token=():, score=0.59003\">():</span><span style=\"background-color: #fffddc\" title=\"token=\n, score=0.18355\">\n</span><span style=\"background-color: #fff6ba\" title=\"token=    , score=0.82242\">    </span><span style=\"background-color: #fea937\" title=\"token=old, score=2.81890\">old</span><span style=\"background-color: #fff9c5\" title=\"token=_, score=0.60808\">_</span><span style=\"background-color: #fee493\" title=\"token=pid, score=1.51105\">pid</span><span style=\"background-color: #fffbd3\" title=\"token= =, score=0.34308\"> =</span><span style=\"background-color: #fff8c1\" title=\"token= current, score=0.68882\"> current</span><span style=\"background-color: #ffffe5\" title=\"token=_, score=0.00021\">_</span><span style=\"background-color: #fffee2\" title=\"token=client, score=0.06909\">client</span><span style=\"background-color: #ffffe4\" title=\"token=_, score=0.02823\">_</span><span style=\"background-color: #ffffe4\" title=\"token=pid, score=0.02497\">pid</span><span style=\"background-color: #fffcd4\" title=\"token=., score=0.31771\">.</span><span style=\"background-color: #ffface\" title=\"token=value, score=0.45923\">value</span><span style=\"background-color: #fffacd\" title=\"token=\n, score=0.48042\">\n</span><span style=\"background-color: #fff0ad\" title=\"token=    , score=1.04268\">    </span><span style=\"background-color: #fece65\" title=\"token=if, score=2.06089\">if</span><span style=\"background-color: #fff8c0\" title=\"token= old, score=0.71230\"> old</span><span style=\"background-color: #ffffe5\" title=\"token=_, score=0.00112\">_</span><span style=\"background-color: #ffffe5\" title=\"token=pid, score=0.00370\">pid</span><span style=\"background-color: #fed778\" title=\"token=!=, score=1.85669\">!=</span><span style=\"background-color: #fec24d\" title=\"token= 0, score=2.36883\"> 0</span><span style=\"background-color: #fffbd3\" title=\"token=:, score=0.36078\">:</span><span style=\"background-color: #fffedf\" title=\"token=\n, score=0.12570\">\n</span><span style=\"background-color: #fffee2\" title=\"token=        , score=0.04929\">        </span><span style=\"background-color: #fea634\" title=\"token=print, score=2.86291\">print</span><span style=\"background-color: #fee89d\" title=\"token=(, score=1.33362\">(</span><span style=\"background-color: #fff8c1\" title=\"token=f, score=0.67868\">f</span><span style=\"background-color: #fff4b5\" title=\"token=\", score=0.91671\">\"</span><span style=\"background-color: #dd5f0c\" title=\"token=B, score=4.23298\">B</span><span style=\"background-color: #fe9a2a\" title=\"token=ooting, score=3.07876\">ooting</span><span style=\"background-color: #f98d23\" title=\"token= previous, score=3.32205\"> previous</span><span style=\"background-color: #fff8c1\" title=\"token= client, score=0.68311\"> client</span><span style=\"background-color: #f98d23\" title=\"token= (, score=3.33903\"> (</span><span style=\"background-color: #fed16b\" title=\"token=pid, score=1.99463\">pid</span><span style=\"background-color: #fed97c\" title=\"token=={, score=1.80338\">={</span><span style=\"background-color: #fffddc\" title=\"token=old, score=0.18544\">old</span><span style=\"background-color: #ffffe5\" title=\"token=_, score=0.00172\">_</span><span style=\"background-color: #ffffe5\" title=\"token=pid, score=0.00118\">pid</span><span style=\"background-color: #fff9c5\" title=\"token=}), score=0.61053\">})</span><span style=\"background-color: #fede86\" title=\"token=\"), score=1.69032\">\")</span><span style=\"background-color: #fffedf\" title=\"token=\n, score=0.12376\">\n</span><span style=\"background-color: #fffcd8\" title=\"token=        , score=0.25020\">        </span><span style=\"background-color: #fec857\" title=\"token=os, score=2.23989\">os</span><span style=\"background-color: #fffee2\" title=\"token=., score=0.05441\">.</span><span style=\"background-color: #fffbcf\" title=\"token=kill, score=0.42256\">kill</span><span style=\"background-color: #fffddd\" title=\"token=(, score=0.16502\">(</span><span style=\"background-color: #fffbd3\" title=\"token=old, score=0.34101\">old</span><span style=\"background-color: #ffffe5\" title=\"token=_, score=0.00022\">_</span><span style=\"background-color: #ffffe5\" title=\"token=pid, score=0.00235\">pid</span><span style=\"background-color: #ffffe4\" title=\"token=,, score=0.02659\">,</span><span style=\"background-color: #fff4b5\" title=\"token= signal, score=0.90316\"> signal</span><span style=\"background-color: #fffee2\" title=\"token=., score=0.05257\">.</span><span style=\"background-color: #fffee1\" title=\"token=S, score=0.07900\">S</span><span style=\"background-color: #fffddc\" title=\"token=IG, score=0.18110\">IG</span><span style=\"background-color: #feeda6\" title=\"token=K, score=1.16605\">K</span><span style=\"background-color: #ffffe5\" title=\"token=ILL, score=0.00019\">ILL</span><span style=\"background-color: #ffffe4\" title=\"token=), score=0.04041\">)</span><span style=\"background-color: #fff9c5\" title=\"token=\n, score=0.61305\">\n</span><span style=\"background-color: #fedd84\" title=\"token=        , score=1.70447\">        </span><span style=\"background-color: #feb13e\" title=\"token=current, score=2.67898\">current</span><span style=\"background-color: #ffffe5\" title=\"token=_, score=0.00114\">_</span><span style=\"background-color: #fffddd\" title=\"token=client, score=0.14712\">client</span><span style=\"background-color: #fffedf\" title=\"token=_, score=0.13217\">_</span><span style=\"background-color: #fffedf\" title=\"token=pid, score=0.13352\">pid</span><span style=\"background-color: #fffcd8\" title=\"token=., score=0.24286\">.</span><span style=\"background-color: #fffcd4\" title=\"token=value, score=0.33288\">value</span><span style=\"background-color: #fffee0\" title=\"token= =, score=0.10250\"> =</span><span style=\"background-color: #fffbd2\" title=\"token= os, score=0.36821\"> os</span><span style=\"background-color: #ffffe5\" title=\"token=., score=0.01062\">.</span><span style=\"background-color: #fffbd0\" title=\"token=get, score=0.40989\">get</span><span style=\"background-color: #fffddb\" title=\"token=pid, score=0.21646\">pid</span><span style=\"background-color: #ffffe5\" title=\"token=(), score=0.00881\">()</span></code></pre>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "html = get_html(code_example)\n",
    "display(HTML(html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reentrancy** example:\n",
    "```solidity\n",
    "function Collect(uint _am)\n",
    "public\n",
    "payable\n",
    "{\n",
    "    if(balances[msg.sender]>=MinSum && balances[msg.sender]>=_am)\n",
    "    {\n",
    "        if(msg.sender.call.value(_am)())\n",
    "        {\n",
    "            balances[msg.sender]-=_am;\n",
    "            Log.AddMessage(msg.sender,_am,\"Collect\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PATTERN_SMARTBUGS = r\"\\s*\\/\\/ <yes> <report> [A-Z_]+\"\n",
    "\n",
    "smart_contract = \"\"\"    function withdraw() {\n",
    "        withdrawalCounter += 1;\n",
    "        // calculate the fibonacci number for the current withdrawal user\n",
    "        // this sets calculatedFibNumber\n",
    "        // <yes> <report> ACCESS_CONTROL\n",
    "        require(fibonacciLibrary.delegatecall(fibSig, withdrawalCounter));\n",
    "        msg.sender.transfer(calculatedFibNumber * 1 ether);\n",
    "    }\n",
    "\n",
    "    // allow users to call fibonacci library functions\n",
    "    function() public {\n",
    "        // <yes> <report> ACCESS_CONTROL\n",
    "        require(fibonacciLibrary.delegatecall(msg.data));\n",
    "    }\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 12]\n",
      "    function withdraw() {\n",
      "        withdrawalCounter += 1;\n",
      "        // calculate the fibonacci number for the current withdrawal user\n",
      "        // this sets calculatedFibNumber\n",
      "        require(fibonacciLibrary.delegatecall(fibSig, withdrawalCounter));\n",
      "        msg.sender.transfer(calculatedFibNumber * 1 ether);\n",
      "    }\n",
      "\n",
      "    // allow users to call fibonacci library functions\n",
      "    function() public {\n",
      "        require(fibonacciLibrary.delegatecall(msg.data));\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "def get_raw_code_and_tgt_line_numbers(annotation_pattern: str, annotated_code: str, verbose=False) -> Tuple[str, List[int]]:\n",
    "    \"\"\"\n",
    "    Remove lines that match the regular expression and extract their line numbers.\n",
    "    \"\"\"\n",
    "    line_numbers: List[int] = []\n",
    "    line_number = 1\n",
    "    new_lines = []\n",
    "    for line in smart_contract.split('\\n'):\n",
    "        match = re.match(annotation_pattern, line)\n",
    "        if match:\n",
    "            logging.debug(f\"Match found in line {line_number}: {line}\")\n",
    "            line_numbers.append(line_number)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "        line_number += 1\n",
    "    raw_code: str = '\\n'.join(new_lines)\n",
    "    logging.debug(f\"Raw code (without annotation): {raw_code}\")\n",
    "    return line_numbers, raw_code\n",
    "\n",
    "line_numbers, raw_code = get_raw_code_and_tgt_line_numbers(PATTERN_SMARTBUGS, smart_contract)\n",
    "print(line_numbers)\n",
    "print(raw_code)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detecting-fake-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d326f5c1b5508426345996e5494dd1240239c10c668b72b11a42af14375058c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
