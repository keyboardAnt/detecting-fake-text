{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = code_example = \\\n",
    "\"\"\"# Handshake successful, kill previous client if there is any.\n",
    "with current_client_pid.get_lock():\n",
    "    old_pid = current_client_pid.value\n",
    "    if old_pid != 0:\n",
    "        print(f\"Booting previous client (pid={old_pid})\")\n",
    "        os.kill(old_pid, signal.SIGKILL)\n",
    "        current_client_pid.value = os.getpid()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  CodeGenForCausalLM\n",
      "Adding bos token...\n",
      "Input:\n",
      "<|endoftext|># Handshake successful, kill previous client if there is any.\n",
      "with current_client_pid.get_lock():\n",
      "    old_pid = current_client_pid.value\n",
      "    if old_pid != 0:\n",
      "        print(f\"Booting previous client (pid={old_pid})\")\n",
      "        os.kill(old_pid, signal.SIGKILL)\n",
      "        current_client_pid.value = os.getpid()\n",
      "------\n",
      "Input token ids' shape:  torch.Size([98])\n",
      "Device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadavt/opt/anaconda3/envs/detecting-fake-text/lib/python3.8/site-packages/transformers/models/codegen/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorCompare.cpp:413.)\n",
      "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding last logit vector...\n",
      "logits.shape:  torch.Size([97, 51200])\n",
      "scores.shape:  torch.Size([97])\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "def get_src_tokens_and_logits(in_text: str, model_name: str, device: str = None) -> Tuple[List[str], Tensor]:\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    print('Model: ', model.__class__.__name__)\n",
    "    print('Adding bos token...')\n",
    "    in_text = f'{tokenizer.bos_token}{in_text}'\n",
    "    print('Input:')\n",
    "    print(in_text)\n",
    "    print('------')\n",
    "    inputs: Tensor = tokenizer(in_text, return_tensors='pt').data['input_ids'].squeeze()\n",
    "    print(\"Input token ids' shape: \", inputs.shape)\n",
    "    if not device:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Device: ', device)\n",
    "    outputs: Tensor = model(inputs.to(torch.device(device)))\n",
    "    # NOTE: The last logit vector is used for predicting the next token, which is not part of the input. Therefore, we exclude it.\n",
    "    print('Discarding last logit vector...')\n",
    "    logits: Tensor = outputs.logits.data[:-1]\n",
    "    print('logits.shape: ', logits.shape)\n",
    "    # tokens: List[str] = tokenizer.convert_ids_to_tokens(inputs[1:])\n",
    "    src_tokens: List[str] = tokenizer.batch_decode([[i] for i in inputs[1:]])\n",
    "    return src_tokens, logits\n",
    "\n",
    "def get_scores(logits: Tensor) -> Tensor:\n",
    "    ret: Tensor = torch.distributions.Categorical(logits=logits).entropy()\n",
    "    print('scores.shape: ', ret.shape)\n",
    "    return ret\n",
    "\n",
    "# def get_topk(logits: Tensor, topk: int = 5):\n",
    "#     topk_prob_values, topk_prob_inds = torch.topk(logits, k=topk, dim=1)\n",
    "#     return topk_prob_values, topk_prob_inds\n",
    "\n",
    "# tokens, logits = get_src_tokens_and_logits(code_example, model_name='Salesforce/codegen-350M-mono')\n",
    "# scores = get_scores(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits -= logits.min(dim=-1, keepdim=True).values\n",
    "# logits /= logits.max(dim=-1, keepdim=True).values\n",
    "# logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_colors(scores: Tensor) -> List[str]:\n",
    "    cmap = mpl.colormaps['YlOrBr']\n",
    "    rgbas: np.ndarray = cmap(scores)\n",
    "    return np.apply_along_axis(mpl.colors.rgb2hex, -1, rgbas)\n",
    "\n",
    "def get_html(in_text: str):\n",
    "        tokens, logits = get_src_tokens_and_logits(in_text, model_name='Salesforce/codegen-350M-mono')\n",
    "        scores = get_scores(logits)\n",
    "        colors = get_colors(scores)\n",
    "        assert len(tokens) == len(colors), f'len(tokens)={len(tokens)} != len(colors)={len(colors)}'\n",
    "        ret = ''.join([f'<span style=\"background-color: {c}\" title=\"token={t}, score={s:.5d}\">{t}</span>' for t, s, c in zip(tokens, scores, colors)])\n",
    "        return f'<pre><code class=\"python\">{ret}</code></pre>'\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_html,\n",
    "    inputs=gr.Textbox(label='Code example', placeholder=code_example, value=code_example),\n",
    "    outputs=gr.Markdown()\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  CodeGenForCausalLM\n",
      "Adding bos token...\n",
      "Input:\n",
      "<|endoftext|># Handshake successful, kill previous client if there is any.\n",
      "with current_client_pid.get_lock():\n",
      "    old_pid = current_client_pid.value\n",
      "    if old_pid != 0:\n",
      "        print(f\"Booting previous client (pid={old_pid})\")\n",
      "        os.kill(old_pid, signal.SIGKILL)\n",
      "        current_client_pid.value = os.getpid()\n",
      "------\n",
      "Input token ids' shape:  torch.Size([98])\n",
      "Device:  cpu\n",
      "Discarding last logit vector...\n",
      "logits.shape:  torch.Size([97, 51200])\n",
      "scores.shape:  torch.Size([97])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><code class=\"python\"><span style=\"background-color: #662506\" title=\"4.11537504196167\">#</span><span style=\"background-color: #662506\" title=\"4.577645778656006\"> Hand</span><span style=\"background-color: #662506\" title=\"2.8311357498168945\">shake</span><span style=\"background-color: #662506\" title=\"5.939050197601318\"> successful</span><span style=\"background-color: #662506\" title=\"3.8849453926086426\">,</span><span style=\"background-color: #662506\" title=\"6.198978424072266\"> kill</span><span style=\"background-color: #662506\" title=\"5.269250392913818\"> previous</span><span style=\"background-color: #662506\" title=\"5.726381301879883\"> client</span><span style=\"background-color: #662506\" title=\"2.6290676593780518\"> if</span><span style=\"background-color: #662506\" title=\"4.383671760559082\"> there</span><span style=\"background-color: #662506\" title=\"1.9891939163208008\"> is</span><span style=\"background-color: #662506\" title=\"2.325011968612671\"> any</span><span style=\"background-color: #662506\" title=\"1.7536401748657227\">.</span><span style=\"background-color: #662506\" title=\"1.1009153127670288\">\n",
       "</span><span style=\"background-color: #662506\" title=\"2.0649654865264893\">with</span><span style=\"background-color: #662506\" title=\"3.5541763305664062\"> current</span><span style=\"background-color: #fec24d\" title=\"0.38006845116615295\">_</span><span style=\"background-color: #662506\" title=\"2.9425487518310547\">client</span><span style=\"background-color: #662506\" title=\"2.0407369136810303\">_</span><span style=\"background-color: #662506\" title=\"4.402245044708252\">pid</span><span style=\"background-color: #662506\" title=\"2.2244834899902344\">.</span><span style=\"background-color: #662506\" title=\"3.766726493835449\">get</span><span style=\"background-color: #fecc61\" title=\"0.34031081199645996\">_</span><span style=\"background-color: #662506\" title=\"1.4840662479400635\">lock</span><span style=\"background-color: #f17b1a\" title=\"0.5900296568870544\">():</span><span style=\"background-color: #ffeea9\" title=\"0.18355166912078857\">\n",
       "</span><span style=\"background-color: #ae3e03\" title=\"0.8224189281463623\">    </span><span style=\"background-color: #662506\" title=\"2.818899154663086\">old</span><span style=\"background-color: #ee7617\" title=\"0.6080794930458069\">_</span><span style=\"background-color: #662506\" title=\"1.51104736328125\">pid</span><span style=\"background-color: #fecc61\" title=\"0.34307512640953064\"> =</span><span style=\"background-color: #db5d0b\" title=\"0.6888224482536316\"> current</span><span style=\"background-color: #ffffe5\" title=\"0.0002123211743310094\">_</span><span style=\"background-color: #fffbcf\" title=\"0.06908563524484634\">client</span><span style=\"background-color: #fffddc\" title=\"0.028226152062416077\">_</span><span style=\"background-color: #fffddd\" title=\"0.024974068626761436\">pid</span><span style=\"background-color: #fed26d\" title=\"0.31771376729011536\">.</span><span style=\"background-color: #fea736\" title=\"0.4592331647872925\">value</span><span style=\"background-color: #fea030\" title=\"0.4804207980632782\">\n",
       "</span><span style=\"background-color: #662506\" title=\"1.0426796674728394\">    </span><span style=\"background-color: #662506\" title=\"2.060887098312378\">if</span><span style=\"background-color: #d55607\" title=\"0.7122979164123535\"> old</span><span style=\"background-color: #ffffe5\" title=\"0.0011161857983097434\">_</span><span style=\"background-color: #ffffe5\" title=\"0.003695825580507517\">pid</span><span style=\"background-color: #662506\" title=\"1.8566880226135254\">!=</span><span style=\"background-color: #662506\" title=\"2.3688266277313232\"> 0</span><span style=\"background-color: #fec857\" title=\"0.36078330874443054\">:</span><span style=\"background-color: #fff7bc\" title=\"0.1256994754076004\">\n",
       "</span><span style=\"background-color: #fffcd6\" title=\"0.04929426312446594\">        </span><span style=\"background-color: #662506\" title=\"2.8629136085510254\">print</span><span style=\"background-color: #662506\" title=\"1.3336248397827148\">(</span><span style=\"background-color: #de610c\" title=\"0.6786842942237854\">f</span><span style=\"background-color: #882f05\" title=\"0.916709840297699\">\"</span><span style=\"background-color: #662506\" title=\"4.23298454284668\">B</span><span style=\"background-color: #662506\" title=\"3.0787649154663086\">ooting</span><span style=\"background-color: #662506\" title=\"3.3220462799072266\"> previous</span><span style=\"background-color: #dd5f0c\" title=\"0.6831128001213074\"> client</span><span style=\"background-color: #662506\" title=\"3.339033603668213\"> (</span><span style=\"background-color: #662506\" title=\"1.9946309328079224\">pid</span><span style=\"background-color: #662506\" title=\"1.8033838272094727\">={</span><span style=\"background-color: #ffeea8\" title=\"0.18543678522109985\">old</span><span style=\"background-color: #ffffe5\" title=\"0.001719964318908751\">_</span><span style=\"background-color: #ffffe5\" title=\"0.001176319201476872\">pid</span><span style=\"background-color: #ee7416\" title=\"0.6105266809463501\">})</span><span style=\"background-color: #662506\" title=\"1.6903157234191895\">\")</span><span style=\"background-color: #fff7bd\" title=\"0.12375709414482117\">\n",
       "</span><span style=\"background-color: #fee390\" title=\"0.2501998543739319\">        </span><span style=\"background-color: #662506\" title=\"2.239891767501831\">os</span><span style=\"background-color: #fffcd4\" title=\"0.05441165342926979\">.</span><span style=\"background-color: #feb340\" title=\"0.4225616157054901\">kill</span><span style=\"background-color: #fff1ae\" title=\"0.16502201557159424\">(</span><span style=\"background-color: #fecc61\" title=\"0.3410130739212036\">old</span><span style=\"background-color: #ffffe5\" title=\"0.0002185957127949223\">_</span><span style=\"background-color: #ffffe5\" title=\"0.0023466760758310556\">pid</span><span style=\"background-color: #fffddd\" title=\"0.026590650901198387\">,</span><span style=\"background-color: #8c3004\" title=\"0.9031592011451721\"> signal</span><span style=\"background-color: #fffcd4\" title=\"0.05256691202521324\">.</span><span style=\"background-color: #fffacb\" title=\"0.07900173217058182\">S</span><span style=\"background-color: #ffeea9\" title=\"0.18109863996505737\">IG</span><span style=\"background-color: #662506\" title=\"1.1660504341125488\">K</span><span style=\"background-color: #ffffe5\" title=\"0.0001938143977895379\">ILL</span><span style=\"background-color: #fffcd8\" title=\"0.040406931191682816\">)</span><span style=\"background-color: #ee7416\" title=\"0.6130450963973999\">\n",
       "</span><span style=\"background-color: #662506\" title=\"1.7044652700424194\">        </span><span style=\"background-color: #662506\" title=\"2.6789793968200684\">current</span><span style=\"background-color: #ffffe5\" title=\"0.0011416058987379074\">_</span><span style=\"background-color: #fff4b5\" title=\"0.14712123572826385\">client</span><span style=\"background-color: #fff6ba\" title=\"0.132171168923378\">_</span><span style=\"background-color: #fff6b9\" title=\"0.1335216611623764\">pid</span><span style=\"background-color: #fee493\" title=\"0.24286341667175293\">.</span><span style=\"background-color: #fece65\" title=\"0.33287906646728516\">value</span><span style=\"background-color: #fff8c4\" title=\"0.10250413417816162\"> =</span><span style=\"background-color: #fec652\" title=\"0.3682122528553009\"> os</span><span style=\"background-color: #fffee2\" title=\"0.010623645968735218\">.</span><span style=\"background-color: #feb945\" title=\"0.4098852276802063\">get</span><span style=\"background-color: #fee89d\" title=\"0.2164595127105713\">pid</span><span style=\"background-color: #fffee2\" title=\"0.008813691325485706\">()</span></code></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "html = get_html(code_example)\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detecting-fake-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d326f5c1b5508426345996e5494dd1240239c10c668b72b11a42af14375058c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
